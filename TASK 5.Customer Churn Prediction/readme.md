# Customer Churn Prediction Using Artificial Neural Network (ANN)

A machine learning project that predicts customer churn using deep learning techniques with TensorFlow/Keras. This project analyzes telecom customer data to identify patterns that indicate whether a customer is likely to churn (leave the service).

## üìã Table of Contents
- [Overview](#overview)
- [Features](#features)
- [Dataset](#dataset)
- [Installation](#installation)
- [Data Processing Pipeline](#data-processing-pipeline)
- [Model Architecture](#model-architecture)
- [Results](#results)
- [Performance Metrics](#performance-metrics)
- [Visualizations](#visualizations)

## üîç Overview

Customer churn prediction is a critical business problem for subscription-based services. This project uses an Artificial Neural Network (ANN) to predict whether customers will churn based on their usage patterns, demographics, and service preferences.

**Key Objectives:**
- Predict customer churn with high accuracy
- Identify key factors contributing to customer churn
- Provide actionable insights for customer retention strategies
- Demonstrate end-to-end machine learning pipeline implementation

## ‚ú® Features

- **Data Preprocessing**: Comprehensive data cleaning and feature engineering
- **Exploratory Data Analysis**: Visual analysis of churn patterns
- **Feature Engineering**: One-hot encoding, normalization, and data transformation
- **Deep Learning Model**: Custom ANN architecture with TensorFlow/Keras
- **Model Evaluation**: Detailed performance metrics and confusion matrix analysis
- **Visualizations**: Interactive plots for data insights and model performance

## üìä Dataset

- **Source**: Telecom customer churn dataset (`customer_churn.csv`)
- **Size**: ~7,000 customer records
- **Features**: 21 attributes including demographics, services, and billing information
- **Target Variable**: Churn (Yes/No) - whether customer left the service

### Key Features:
- **Demographics**: Gender, Senior Citizen status, Partner, Dependents
- **Services**: Phone Service, Internet Service, Multiple Lines, Online Security
- **Account Info**: Tenure, Contract type, Payment method, Monthly charges
- **Billing**: Total charges, Paperless billing

## üöÄ Installation

### Prerequisites
- Python 3.7+
- Jupyter Notebook or JupyterLab

### Required Libraries
```bash
# Core data science libraries
pip install pandas numpy matplotlib seaborn

# Machine learning libraries
pip install scikit-learn tensorflow

# Optional: For enhanced visualizations
pip install plotly
```


## üîÑ Data Processing Pipeline

### 1. Data Loading and Exploration
- Load customer churn dataset
- Explore data structure and identify missing values
- Analyze target variable distribution

### 2. Data Cleaning
- Remove unnecessary columns (customerID)
- Handle missing values in TotalCharges column
- Convert data types appropriately

### 3. Exploratory Data Analysis
- Visualize churn patterns by tenure
- Analyze monthly charges distribution
- Identify key churn indicators

### 4. Feature Engineering
- **Binary Encoding**: Convert Yes/No columns to 1/0
- **Gender Encoding**: Convert Male/Female to 0/1
- **One-Hot Encoding**: Handle categorical variables (InternetService, Contract, PaymentMethod)
- **Feature Scaling**: Normalize numerical features using MinMaxScaler

### 5. Data Preparation
- Split data into training and testing sets (80/20 split)
- Prepare features (X) and target variable (y)

## üß† Model Architecture

### Neural Network Structure
```
Input Layer (26 features)
    ‚Üì
Hidden Layer 1 (26 neurons, ReLU activation)
    ‚Üì
Hidden Layer 2 (15 neurons, ReLU activation)
    ‚Üì
Output Layer (1 neuron, Sigmoid activation)
```

### Model Configuration
- **Optimizer**: Adam
- **Loss Function**: Binary Crossentropy
- **Metrics**: Accuracy
- **Training Epochs**: 100
- **Batch Size**: Default (32)

### Model Compilation
```python
model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)
```

## üìä Results

### Model Performance
- **Test Accuracy**: ~77.5%
- **Training completed**: 100 epochs
- **Prediction threshold**: 0.5

### Key Insights
- Customers with shorter tenure are more likely to churn
- Monthly charges distribution shows distinct patterns between churned and retained customers
- Service-related features significantly impact churn probability

## üìà Performance Metrics

### Confusion Matrix Analysis
```
Actual vs Predicted:
- True Negatives (TN): 862 (Correctly predicted non-churn)
- False Positives (FP): 179 (Incorrectly predicted churn)
- False Negatives (FN): 137 (Missed churn predictions)
- True Positives (TP): 229 (Correctly predicted churn)
```

### Calculated Metrics
- **Overall Accuracy**: 77% ((862+229)/(862+229+137+179))
- **Precision (Non-Churn)**: 83% (862/(862+179))
- **Precision (Churn)**: 63% (229/(229+137))
- **Recall (Non-Churn)**: 86% (862/(862+137))

### Classification Report
The model provides detailed precision, recall, and F1-scores for both classes, enabling comprehensive performance evaluation.

## üìä Visualizations

The project generates several key visualizations:

1. **Churn Distribution by Tenure**: Histogram showing customer tenure patterns
2. **Monthly Charges Analysis**: Distribution comparison between churned and retained customers
3. **Confusion Matrix Heatmap**: Visual representation of model predictions
4. **Feature Importance**: Analysis of key factors affecting churn

## üõ†Ô∏è Dependencies

### Core Libraries
- `pandas`: Data manipulation and analysis
- `numpy`: Numerical computing
- `matplotlib`: Basic plotting and visualization
- `seaborn`: Statistical data visualization

### Machine Learning Libraries
- `scikit-learn`: Data preprocessing and metrics
- `tensorflow`: Deep learning framework
- `keras`: High-level neural network API (included in TensorFlow)

### Specific Modules Used
- `sklearn.preprocessing.MinMaxScaler`: Feature scaling
- `sklearn.model_selection.train_test_split`: Data splitting
- `sklearn.metrics`: Performance evaluation
- `tensorflow.keras`: Neural network implementation

## üîß Model Hyperparameters

### Tunable Parameters
- **Learning Rate**: Default Adam optimizer settings
- **Network Architecture**: 26 ‚Üí 15 ‚Üí 1 neurons
- **Activation Functions**: ReLU (hidden), Sigmoid (output)
- **Training Epochs**: 100 (adjustable)
- **Batch Size**: 32 (default)

### Feature Scaling
- **Method**: MinMaxScaler (0-1 normalization)
- **Applied to**: tenure, MonthlyCharges, TotalCharges

## üìà Business Impact

### Actionable Insights
- **Early Warning System**: Identify at-risk customers proactively
- **Targeted Retention**: Focus efforts on high-risk customer segments
- **Cost Optimization**: Reduce customer acquisition costs through better retention
- **Revenue Protection**: Prevent revenue loss from customer churn

### Use Cases
- Customer retention campaigns
- Personalized offers for at-risk customers
- Resource allocation for customer success teams
- Strategic business planning

## üîÆ Future Enhancements

- [ ] **Hyperparameter Tuning**: Grid search for optimal model parameters
- [ ] **Feature Engineering**: Create additional derived features
- [ ] **Model Ensemble**: Combine multiple algorithms for better performance
- [ ] **Real-time Prediction**: Deploy model for live churn prediction
- [ ] **A/B Testing**: Validate model performance in production
- [ ] **Advanced Visualizations**: Interactive dashboards with Plotly/Dash
- [ ] **Model Interpretability**: SHAP values for feature importance
- [ ] **Cross-validation**: More robust model evaluation

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## üìù Notes

- **Data Quality**: Ensure proper handling of missing values and outliers
- **Feature Selection**: Consider feature importance for model optimization
- **Model Monitoring**: Regular retraining recommended for production use
- **Scalability**: Current model suitable for datasets up to 100K records

## üèÜ Model Performance Summary

| Metric | Value |
|--------|-------|
| Accuracy | 77.5% |
| Precision (No Churn) | 83% |
| Precision (Churn) | 63% |
| Recall (No Churn) | 86% |
| Training Time | ~2-3 minutes |
| Model Size | ~50KB |

